Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/home1/scur2673/deep-learning-2/.venv/lib64/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=8` in the `DataLoader` to improve performance.
Loading evaluation dataset...
Running evaluation...
Validation: |          | 0/? [00:00<?, ?it/s]Validation:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:02,  6.43it/s]Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:01, 12.57it/s]Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 18.44it/s]Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 24.07it/s]Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 29.48it/s]Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 34.68it/s]Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 39.69it/s]Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 44.50it/s]Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 49.15it/s]Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 53.64it/s]Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 57.98it/s]Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 62.16it/s]Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 66.21it/s]Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 70.16it/s]Validation DataLoader 0:  94%|█████████▍| 15/16 [00:00<00:00, 73.98it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 77.71it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 73.70it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     Validate metric           DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         val_acc                    1.0
        val_loss           0.0010067439870908856
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Evaluation results: [{'val_loss': 0.0010067439870908856, 'val_acc': 1.0}]
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/home1/scur2673/deep-learning-2/.venv/lib64/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=8` in the `DataLoader` to improve performance.
Loading evaluation dataset...
Running evaluation...
Validation: |          | 0/? [00:00<?, ?it/s]Validation:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:02,  7.38it/s]Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.36it/s]Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 21.01it/s]Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 27.36it/s]Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 33.45it/s]Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 39.25it/s]Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 44.81it/s]Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 50.14it/s]Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 55.26it/s]Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 60.16it/s]Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 64.88it/s]Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 69.49it/s]Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 73.86it/s]Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 78.08it/s]Validation DataLoader 0:  94%|█████████▍| 15/16 [00:00<00:00, 82.15it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 86.17it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 81.53it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     Validate metric           DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         val_acc            0.9950000047683716
        val_loss           0.020804673433303833
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Evaluation results: [{'val_loss': 0.020804673433303833, 'val_acc': 0.9950000047683716}]
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/home1/scur2673/deep-learning-2/.venv/lib64/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=8` in the `DataLoader` to improve performance.
Loading evaluation dataset...
Running evaluation...
Validation: |          | 0/? [00:00<?, ?it/s]Validation:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:02,  7.47it/s]Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.53it/s]Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 21.25it/s]Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 27.67it/s]Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 33.80it/s]Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 39.61it/s]Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 45.21it/s]Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 50.58it/s]Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 55.76it/s]Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 60.68it/s]Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 65.47it/s]Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 70.09it/s]Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 74.51it/s]Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 78.77it/s]Validation DataLoader 0:  94%|█████████▍| 15/16 [00:00<00:00, 82.89it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 86.92it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 82.19it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     Validate metric           DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         val_acc            0.9679999947547913
        val_loss            0.09168930351734161
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Evaluation results: [{'val_loss': 0.09168930351734161, 'val_acc': 0.9679999947547913}]
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/home1/scur2673/deep-learning-2/.venv/lib64/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=8` in the `DataLoader` to improve performance.
Loading evaluation dataset...
Running evaluation...
Validation: |          | 0/? [00:00<?, ?it/s]Validation:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01,  8.08it/s]Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 15.66it/s]Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 22.84it/s]Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 29.62it/s]Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 36.04it/s]Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 42.22it/s]Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 48.11it/s]Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 53.75it/s]Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 59.13it/s]Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 64.31it/s]Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 69.27it/s]Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 74.05it/s]Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 78.61it/s]Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 83.03it/s]Validation DataLoader 0:  94%|█████████▍| 15/16 [00:00<00:00, 87.25it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 91.39it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 86.35it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     Validate metric           DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         val_acc            0.9269999861717224
        val_loss            0.19959677755832672
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Evaluation results: [{'val_loss': 0.19959677755832672, 'val_acc': 0.9269999861717224}]
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/home1/scur2673/deep-learning-2/.venv/lib64/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=8` in the `DataLoader` to improve performance.
Loading evaluation dataset...
Running evaluation...
Validation: |          | 0/? [00:00<?, ?it/s]Validation:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:02,  7.44it/s]Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 14.47it/s]Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 21.16it/s]Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 27.54it/s]Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 33.65it/s]Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 39.43it/s]Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 45.00it/s]Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 50.34it/s]Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 55.50it/s]Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 60.40it/s]Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 65.15it/s]Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 69.75it/s]Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 74.16it/s]Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 78.35it/s]Validation DataLoader 0:  94%|█████████▍| 15/16 [00:00<00:00, 82.43it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 86.41it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 81.77it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     Validate metric           DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         val_acc            0.8880000114440918
        val_loss            0.2634172737598419
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Evaluation results: [{'val_loss': 0.2634172737598419, 'val_acc': 0.8880000114440918}]
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/home1/scur2673/deep-learning-2/.venv/lib64/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=8` in the `DataLoader` to improve performance.
Loading evaluation dataset...
Running evaluation...
Validation: |          | 0/? [00:00<?, ?it/s]Validation:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01,  8.06it/s]Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 15.62it/s]Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 22.76it/s]Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 29.48it/s]Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 35.94it/s]Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 42.07it/s]Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 47.95it/s]Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 53.52it/s]Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 58.89it/s]Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 64.03it/s]Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 68.97it/s]Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 73.70it/s]Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 78.26it/s]Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 82.62it/s]Validation DataLoader 0:  94%|█████████▍| 15/16 [00:00<00:00, 86.84it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 90.94it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 85.89it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     Validate metric           DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         val_acc            0.9950000047683716
        val_loss           0.015356593765318394
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Evaluation results: [{'val_loss': 0.015356593765318394, 'val_acc': 0.9950000047683716}]
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/home1/scur2673/deep-learning-2/.venv/lib64/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=8` in the `DataLoader` to improve performance.
Loading evaluation dataset...
Running evaluation...
Validation: |          | 0/? [00:00<?, ?it/s]Validation:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01,  7.96it/s]Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 15.42it/s]Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 22.52it/s]Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 29.27it/s]Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 35.69it/s]Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 41.81it/s]Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 47.66it/s]Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 53.24it/s]Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 58.59it/s]Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 63.72it/s]Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 68.64it/s]Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 73.39it/s]Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 77.92it/s]Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 82.31it/s]Validation DataLoader 0:  94%|█████████▍| 15/16 [00:00<00:00, 86.51it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 90.63it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 85.49it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     Validate metric           DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         val_acc            0.9980000257492065
        val_loss           0.005620510783046484
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Evaluation results: [{'val_loss': 0.005620510783046484, 'val_acc': 0.9980000257492065}]
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
/gpfs/home1/scur2673/deep-learning-2/.venv/lib64/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=8` in the `DataLoader` to improve performance.
Loading evaluation dataset...
Running evaluation...
Validation: |          | 0/? [00:00<?, ?it/s]Validation:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]Validation DataLoader 0:   6%|▋         | 1/16 [00:00<00:01,  8.07it/s]Validation DataLoader 0:  12%|█▎        | 2/16 [00:00<00:00, 15.64it/s]Validation DataLoader 0:  19%|█▉        | 3/16 [00:00<00:00, 22.82it/s]Validation DataLoader 0:  25%|██▌       | 4/16 [00:00<00:00, 29.65it/s]Validation DataLoader 0:  31%|███▏      | 5/16 [00:00<00:00, 36.16it/s]Validation DataLoader 0:  38%|███▊      | 6/16 [00:00<00:00, 42.35it/s]Validation DataLoader 0:  44%|████▍     | 7/16 [00:00<00:00, 48.29it/s]Validation DataLoader 0:  50%|█████     | 8/16 [00:00<00:00, 53.92it/s]Validation DataLoader 0:  56%|█████▋    | 9/16 [00:00<00:00, 59.34it/s]Validation DataLoader 0:  62%|██████▎   | 10/16 [00:00<00:00, 64.53it/s]Validation DataLoader 0:  69%|██████▉   | 11/16 [00:00<00:00, 69.50it/s]Validation DataLoader 0:  75%|███████▌  | 12/16 [00:00<00:00, 74.29it/s]Validation DataLoader 0:  81%|████████▏ | 13/16 [00:00<00:00, 78.88it/s]Validation DataLoader 0:  88%|████████▊ | 14/16 [00:00<00:00, 83.29it/s]Validation DataLoader 0:  94%|█████████▍| 15/16 [00:00<00:00, 87.53it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 91.69it/s]Validation DataLoader 0: 100%|██████████| 16/16 [00:00<00:00, 86.24it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     Validate metric           DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         val_acc           0.007000000216066837
        val_loss             9.407882690429688
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Evaluation results: [{'val_loss': 9.407882690429688, 'val_acc': 0.007000000216066837}]

JOB STATISTICS
==============
Job ID: 12045847
Cluster: snellius
User/Group: scur2673/scur2673
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:01:21
CPU Efficiency: 5.29% of 00:25:30 core-walltime
Job Wall-clock time: 00:01:25
Memory Utilized: 7.03 MB
Memory Efficiency: 0.01% of 120.00 GB (120.00 GB/node)
